{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117a6c1f-21ad-456f-881d-030b8db554e4",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Dict, Any, Optional, Callable\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.registration import register, registry\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# from typing import Any, Dict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be75fa0-2c7f-41f1-9b23-59fc3388e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders for logs and videos\n",
    "log_folder = './marl_logs'\n",
    "video_folder = os.path.join(log_folder, 'video')\n",
    "os.makedirs(video_folder, exist_ok=True)\n",
    "# PPO.load(os.path.join(log_folder, 'optuna/best_model/best_model.zip'), device='cpu').policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3925f65e-545b-485c-a6a1-78d39d79a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir {log_folder} --host=0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8432d5-ff64-4cda-b690-0cbf42c7191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'MarineEnv-v0' not in registry:\n",
    "    register(\n",
    "        id='MarineEnv-v0',\n",
    "        entry_point='marl:MarineEnv',  # String reference to the class\n",
    "    )\n",
    "\n",
    "def yield_random_seed():\n",
    "    while True:\n",
    "        yield np.random.randint(low=1, high=201)\n",
    "seed_generator = yield_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13b1c19-a160-40fe-b6a4-75ebadbd7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = dict(\n",
    "        render_mode='rgb_array',\n",
    "        training_stage=2,\n",
    "        timescale=1/3,\n",
    "        training=False,\n",
    "        total_targets=2,\n",
    "    )\n",
    "    \n",
    "env = gym.make(\n",
    "        'MarineEnv-v0',\n",
    "        **env_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81b8f464-be01-4703-bd32-2fac0c130057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual observation space: (71,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual observation space:\", (env.observation_space.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b249aa-1871-4416-ab16-a29c74411c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_video_rendering(\n",
    "    agent: Any, \n",
    "    episodes: int = 3, \n",
    "    timescale: float = 1/6, \n",
    "    seed: Optional[int] = None, \n",
    "    record_video: bool = False, \n",
    "    episode_trigger: Optional[Callable[[int], bool]] = None, \n",
    "    name_prefix: Optional[str] = None, \n",
    "    video_folder: Optional[str] = None,\n",
    "    marl: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Runs a simulation of the MarineEnv-v0 environment using the given agent, with optional video recording.\n",
    "\n",
    "    Parameters:\n",
    "    - agent: The trained agent used for inference.\n",
    "    - episodes (int): Number of episodes to run (default is 3).\n",
    "    - timescale (float): The simulation timescale factor (default is 1/6).\n",
    "    - seed (int, optional): Random seed for environment initialization. If None, a generated seed is used.\n",
    "    - record_video (bool): If True, records the simulation as a video (default is False).\n",
    "    - episode_trigger (function, optional): A function that determines which episodes get recorded.\n",
    "    - name_prefix (str, optional): Prefix for recorded video file names.\n",
    "    - video_folder (str, optional): Path to save recorded videos.\n",
    "    - marl (bool): If True, running the env in MARL mode.\n",
    "\n",
    "    Behavior:\n",
    "    - If video recording is enabled, the environment is wrapped with RecordVideo.\n",
    "    - Logs episode statistics, including total rewards, episode length, and termination status.\n",
    "    - If recording, logs are saved to a text file in the specified video folder.\n",
    "    - Displays simulation results in the console if video recording is disabled.\n",
    "\n",
    "    Returns:\n",
    "    - None. The function either logs the results to a file or prints them to the console.\n",
    "    \"\"\"\n",
    "    \n",
    "    if seed is None:\n",
    "        seed = next(seed_generator)\n",
    "        \n",
    "    kwargs = dict(\n",
    "        render_mode='rgb_array' if record_video else 'human',\n",
    "        continuous=True,\n",
    "        training_stage=2,\n",
    "        timescale=timescale,\n",
    "        training=False,\n",
    "        total_targets=2,\n",
    "        seed=seed,\n",
    "    )\n",
    "    \n",
    "    env = gym.make(\n",
    "        'MarineEnv-v0',\n",
    "        **kwargs,\n",
    "    )\n",
    "    \n",
    "    if record_video:\n",
    "        from IPython.display import HTML\n",
    "        from base64 import b64encode\n",
    "        \n",
    "        if episode_trigger is None:\n",
    "            episode_trigger = lambda episode_id: True\n",
    "\n",
    "        if video_folder is None:\n",
    "            video_folder = video_folder   \n",
    "        else:\n",
    "            if name_prefix:\n",
    "                video_folder = os.path.join(video_folder, name_prefix)\n",
    "        \n",
    "        # wrap environment for video recording\n",
    "        env = RecordVideo(\n",
    "            env=env, \n",
    "            video_folder=video_folder, \n",
    "            episode_trigger=lambda episode_id: True, \n",
    "            name_prefix=name_prefix)\n",
    "        \n",
    "    logged_episodes = []\n",
    "    logged_rewards = []\n",
    "    for episode in range(episodes):\n",
    "        state, _ = env.reset()\n",
    "        episode_rewards = 0\n",
    "\n",
    "        if marl:\n",
    "            eta = state[0][8]\n",
    "        else:\n",
    "            eta = state[8]\n",
    "        \n",
    "        for step in range(int(400 / timescale)):\n",
    "            if marl:\n",
    "                with torch.no_grad():\n",
    "                    actions = [agent.predict(i, deterministic=True)[0] for i in state]\n",
    "                next_state, reward, terminated, truncated, info = env.step(actions)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    action = agent.predict(state, deterministic=True)\n",
    "            \n",
    "                state, reward, terminated, truncated, info = env.step(action[0])\n",
    "            \n",
    "            if not record_video:\n",
    "                env.render()\n",
    "                \n",
    "            episode_rewards += reward\n",
    "            \n",
    "            if terminated or truncated:\n",
    "                break\n",
    "                \n",
    "            time.sleep(0.005)\n",
    "         \n",
    "        result_string = f'Episode: {episode}\\nEpisode length: {step}, Elapsed real time: {round(step * timescale)} minutes, Initial WP ETA: {round(eta)} minutes\\nEpisode total rewards: {episode_rewards :.2f}\\nIs terminated: {info[\"terminated\"]}, Is truncated: {info[\"truncated\"]}\\n============================\\n'\n",
    "\n",
    "        logged_episodes.append(result_string)\n",
    "        logged_rewards.append(episode_rewards)\n",
    "\n",
    "    evaluation = f'Mean: {np.array(logged_rewards).mean():.2f}, Std: {np.array(logged_rewards).std():.2f}, Initial seed: {seed}'\n",
    "    logged_episodes.append(evaluation)\n",
    "    # Open log file\n",
    "    if record_video:\n",
    "        log_file_path = os.path.join(video_folder, name_prefix + '.txt')\n",
    "        with open(log_file_path, 'w') as log_file:\n",
    "            log_file.write('\\n'.join(logged_episodes))\n",
    "            print(f\"Training log saved at: {log_file_path}\")\n",
    "    else:\n",
    "        print('\\n'.join(logged_episodes))\n",
    "    \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d5a25-2623-47bf-8208-108aa5b55755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup of the training envs\n",
    "train_env = make_vec_env(env_id='MarineEnv-v0', n_envs=8, env_kwargs=env_kwargs)\n",
    "eval_env = gym.make('MarineEnv-v0', **env_kwargs)\n",
    "eval_env = Monitor(eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98ccec-060c-4c57-8c15-8882220db84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup of the defaut kwargs for initial training of PPO agent\n",
    "default_kwargs = {\n",
    "    'learning_rate': 3e-4,\n",
    "    'n_steps': 2048,\n",
    "    'batch_size': 64,\n",
    "    'n_epochs': 10,\n",
    "    'gamma': 0.99, \n",
    "    'gae_lambda': 0.95,\n",
    "    'clip_range': 0.2,\n",
    "    'ent_coef': 0.0,\n",
    "    'vf_coef': 0.5, \n",
    "    'max_grad_norm': 0.5,\n",
    "    'target_kl': None,\n",
    "    'tensorboard_log': log_folder,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ff3e7-439c-436d-ad2e-fa1cf5a9d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish initial agent\n",
    "agent = PPO(\n",
    "        policy='MlpPolicy',\n",
    "        env=train_env,\n",
    "        verbose=0,\n",
    "        device='cpu',\n",
    "        **default_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c48c15-9ead-4b1b-bcaa-f60dc7aa9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval callback - used to track the statistics of the training\n",
    "eval_callback = EvalCallback(\n",
    "        eval_env,\n",
    "        best_model_save_path=os.path.join(log_folder, 'default/best_model/'),\n",
    "        log_path=os.path.join(log_folder, 'default/results/'),\n",
    "        eval_freq=5000,\n",
    "        deterministic=True,\n",
    "        render=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d48b29-6651-4b5b-a9be-e7bfe6362cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e10ab-a4ca-466e-bed4-7d1a9d9cd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b4de70-7c4c-4146-8d57-bb95cd415de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.learn(total_timesteps=int(1e5), reset_num_timesteps=True, tb_log_name='default/default_best', progress_bar=True, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f58e2fe-f0c6-4c96-87db-788c6ddb6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "agent = PPO.load('marl_logs/default/best_model/best_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea31075-50e9-4ee1-b60f-8f41a6a02d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_video_rendering(agent, episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1530a7-5fe6-40e5-a035-d124fea616a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_video_rendering(agent, episodes=1, marl=False, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93863a12-3c3a-4ef6-93aa-54855c9af09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = agent.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fb3be2-5c94-4184-b3b7-5e296e99e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_env = env.envs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c686e-65ff-47be-81d0-e94ed0641e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = raw_env\n",
    "while hasattr(env, 'env'):\n",
    "    env = env.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d84368-43d1-4b6d-9f94-aea55a2726e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe95b1b-6ee3-4f4a-a5d7-a6ab5b73828d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "print(\"Step obs:\", obs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e9167-c2c6-4c07-86fa-15735f37653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f263b5b-b94d-4e4a-80d4-9a9432a8988c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
